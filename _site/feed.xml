<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-01-23T09:56:15-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Kartik’s Notebook</title><subtitle>Offload the brain.
</subtitle><author><name>Kartik Pradeepan</name></author><entry><title type="html">Introduction to Machine Learning on AWS</title><link href="http://localhost:4000/jekyll/2024-01-20-AWS_ML.html" rel="alternate" type="text/html" title="Introduction to Machine Learning on AWS" /><published>2024-01-20T00:00:00-05:00</published><updated>2024-01-20T00:00:00-05:00</updated><id>http://localhost:4000/jekyll/AWS_ML</id><content type="html" xml:base="http://localhost:4000/jekyll/2024-01-20-AWS_ML.html"><![CDATA[<p>Artificial intelligence is the larger field of study using computers to do processes generally done by the human brain.</p>

<p>Machine learning is a subset of artificial inteilligence where we work on algorithms that are able to learn from a set of training data.</p>

<p>Deep learning is a subset of machine learning that uses multilayer networks to build a model closer to a human brain.</p>

<p>All AI systems have three parts:
1) Training: supply training data to an algorithm
1) Model: Receive an output of the training process
1) Inference and hosting: use the model to make a prediction</p>

<p>All AWS services are exposed to each other via APIs that can be communicated via SDKs.</p>

<p>Amazon has a number of different ML services:
1) Amazon Rekognition: computer vision
1) Amazon Textract: automated text extraction and analysis
1) Amazon Comprehend: natural language processing
1) Amazon Transcribe: speech to text
1) Amazon Translate: machine langauge translation
1) Amazon Lex: chat bots and virtual agents
1) Amazon Sagemaker: build, train, and deploy your own machine learning models on managed infrastracture.</p>

<h1 id="amazon-rekegnition">Amazon Rekegnition</h1>

<ul>
  <li>Fully managed deep-learning image-recognition service.</li>
  <li>Designed for scalability.</li>
  <li>Capabilities: Recognizes scenes, objects, concepts, faces.</li>
</ul>

<p><strong>Key Features</strong>:</p>
<ul>
  <li>Uses pretrained models.</li>
  <li>APIs provide inferences from these models.</li>
  <li>Detects labels, faces, texts, and specific content like moderation labels and protective equipment in images.</li>
</ul>

<p><strong>API Examples</strong>:</p>
<ul>
  <li><strong>CompareFaces</strong>: Matches faces between a source and target image.</li>
  <li><strong>DetectFaces</strong>: Identifies faces and provides details like age range, presence of smile, etc.</li>
  <li><strong>DetectLabels</strong>: Identifies objects, events, concepts, with a confidence score.</li>
  <li><strong>DetectModerationLabels</strong>: Finds potentially sensitive content.</li>
  <li><strong>DetectProtectiveEquipment</strong>: Identifies face, hand, and head covers.</li>
  <li><strong>DetectText</strong>: Recognizes text in an image.</li>
  <li><strong>Celebrity Recognition</strong>: Identifies celebrities in images.</li>
</ul>

<p><strong>Video Content Analysis</strong>:</p>
<ul>
  <li>Similar operations on stored video content.</li>
  <li>Video-specific APIs for segment detection, person tracking, etc.</li>
</ul>

<p><strong>Collections of Faces APIs</strong>:</p>
<ul>
  <li><strong>CreateCollection</strong>: Creates a collection of faces.</li>
  <li><strong>IndexFaces</strong>: Populates a collection with detected faces.</li>
  <li><strong>Search by Face ID or Image</strong>: Finds matching faces in a collection.</li>
</ul>

<p><strong>Custom Training and Custom Labels</strong>:</p>
<ul>
  <li>Ability to train Rekognition with user’s labeled datasets.</li>
  <li><strong>CreateDataset</strong> and <strong>DetectCustomLabels</strong>: User can create and use custom models for specific recognition tasks.</li>
</ul>

<p><strong>Applications</strong>:</p>
<ul>
  <li>Image search indexing (e.g., vacation rental photos with beach scenes).</li>
  <li>Automating detection of missing parts in factory assembly lines.</li>
  <li>Brand logo recognition in online videos.</li>
</ul>

<h1 id="amazon-textract">Amazon Textract</h1>
<ul>
  <li>Fully managed service for analyzing documents.</li>
  <li>Extracts text and structure, including handwritten documents.</li>
  <li>Built on AWS-trained models.</li>
</ul>

<p><strong>Available APIs</strong>:</p>
<ul>
  <li><strong>AnalyzeDocument</strong>: Analyzes specific features like tables, forms, queries.</li>
  <li><strong>AnalyzeExpense</strong>: Processes expenses from receipts or invoices.</li>
  <li><strong>DetectDocumentText</strong>: Identifies text within a document.</li>
  <li><strong>AnalyzeID</strong>: Extracts information from identity documents like driver’s licenses.</li>
  <li>Asynchronous operation: Start API (begins process, returns job ID), Get API (retrieves status/results).</li>
</ul>

<p><strong>API Responses</strong>:</p>
<ul>
  <li><strong>AnalyzeDocument</strong>: Returns JSON data structure with blocks (page, line, word, key-value sets).</li>
  <li><strong>AnalyzeExpense</strong>: Identifies vendor, sales information from expenses.</li>
  <li><strong>DetectDocumentText</strong>: Provides blocks of text, lines, and words.</li>
  <li><strong>AnalyzeID</strong>: Extracts details from identity documents.</li>
</ul>

<p><strong>Practical Use Case</strong>:</p>
<ul>
  <li>Handwritten movie reviews: determine which API to use for extraction.</li>
  <li>Focus on extracting text and structured data from documents.</li>
</ul>

<h1 id="amazon-comprehend">Amazon Comprehend</h1>
<ul>
  <li>Natural-language-processing machine learning service.</li>
  <li>Extracts insights and connections from text.</li>
  <li>Offers both pre-trained Amazon models and custom model training.</li>
</ul>

<p><strong>APIs for Language and Entity Detection</strong>:</p>
<ul>
  <li><strong>Detect-Dominant-Language</strong>: Real-time and batch processing for language detection.</li>
  <li><strong>Batch-Detect-Dominant-Language</strong>: For batch analysis of up to 25 documents.</li>
  <li><strong>Start-Dominant-Language-Detection-Job</strong>: Asynchronous batch processing with S3 input/output.</li>
  <li><strong>Detect Named Entities</strong>: Identifies entities like persons, organizations in text.</li>
  <li><strong>Detect Key Noun Phrases</strong>: Finds important noun phrases in text.</li>
  <li><strong>Detect Personally Identifying Information</strong>: Identifies and redacts sensitive information.</li>
</ul>

<p><strong>Sentiment Analysis API</strong>:</p>
<ul>
  <li><strong>Detect-Sentiment</strong>: Determines text sentiment (e.g., positive, negative).</li>
</ul>

<p><strong>Custom Model APIs</strong>:</p>
<ul>
  <li><strong>Custom Classification</strong>: Classifies documents using custom labels.</li>
  <li><strong>Custom Entity Recognizer</strong>: Recognizes custom-defined entities in text.</li>
  <li><strong>Start-Document-Classification-Job</strong> and <strong>Start-Entities-Detection-Job</strong>: Asynchronous processing with custom models.</li>
  <li><strong>Classify-Document</strong> and <strong>Detect-Entities</strong>: Real-time processing with purchased endpoints for custom models.</li>
</ul>

<p><strong>Additional APIs and Features</strong>:</p>
<ul>
  <li>Event detection and topic detection.</li>
  <li>
    <p>Detailed AWS Documentation available for more information.</p>
  </li>
  <li><strong>Practical Use Case Scenario</strong>:
    <ul>
      <li>Analyzing movie preview forms for audience sentiment.</li>
      <li>Integrating sentiment analysis with demographic analytics.</li>
    </ul>

    <h1 id="amazon-transcribe">Amazon Transcribe</h1>
    <ul>
      <li>Converts speech to text.</li>
      <li>Utilizes trained models for transcription subtleties.</li>
      <li>Supports 37 languages (as of publishing).</li>
    </ul>
  </li>
</ul>

<p><strong>Transcription Complexity</strong>:</p>
<ul>
  <li>Complex mapping from spoken word to text.</li>
  <li>Examples: Currency and date formats.</li>
</ul>

<p><strong>Transcription APIs</strong>:</p>
<ul>
  <li><strong>StartTranscriptionJob</strong>: Batch processing with media file input.</li>
  <li><strong>GetTranscriptionJob</strong>: Retrieves results and status of transcription jobs.</li>
  <li><strong>StartStreamTranscription</strong>: Real-time transcription for streaming media.</li>
</ul>

<p>Improving Transcription Accuracy**:</p>
<ul>
  <li><strong>Custom Vocabulary</strong>: Enhance transcription of unique terms (e.g., brand names, technical terms).</li>
  <li><strong>Custom-Language Model</strong>: Train with domain-specific text for context recognition.</li>
</ul>

<p><strong>Vocabulary Management</strong>:</p>
<ul>
  <li><strong>Vocabulary Filter</strong>: Masks or filters specific words (e.g., offensive language).</li>
  <li><strong>Content Redaction</strong>: Automatic masking/removal of sensitive information (e.g., credit card numbers).</li>
</ul>

<p><strong>Additional Features</strong>:</p>
<ul>
  <li><strong>Language Identification</strong>: Detects language of the media file.</li>
  <li><strong>Speaker Diarization</strong>: Identifies different speakers in a media file.</li>
</ul>

<p><strong>Specialized Use Cases</strong>:</p>
<ul>
  <li>Medical and call-center analytics.</li>
  <li>Detailed information in AWS Documentation.</li>
</ul>

<p><strong>Practical Application</strong>:</p>
<ul>
  <li>Suitable for diverse scenarios, from everyday conversations to technical and domain-specific dialogues.</li>
</ul>

<h1 id="amazon-translate">Amazon Translate</h1>
<ul>
  <li>Service for text translation between different languages.</li>
  <li>Supports 75 languages (as of course creation).</li>
</ul>

<p><strong>APIs for Translation</strong>:</p>
<ul>
  <li><strong>TranslateText</strong>: Real-time text translation.</li>
  <li><strong>StartTextTranslationJob</strong>: Asynchronous batch translation.</li>
  <li><strong>DescribeTextTranslationJob</strong>: Checks status and results of batch translation jobs.</li>
</ul>

<p><strong>Customization Options</strong>:</p>
<ul>
  <li>Formality setting: Adjusts translation for formal or informal language (supported in French, German, Hindi, Italian, Japanese, Spanish).</li>
  <li>Profanity replacement: Uses grawlix strings for profane words/phrases.</li>
  <li>Custom terminology: Control translations of specific terms, unidirectional or multidirectional.</li>
  <li>Non-translated text tags: Use tags like <code class="language-plaintext highlighter-rouge">&lt;span&gt;</code> or <code class="language-plaintext highlighter-rouge">&lt;p&gt;</code> with <code class="language-plaintext highlighter-rouge">translate=no</code> property to exclude text from translation.</li>
  <li>Parallel data: Customize translation output for specific domains (e.g., life sciences, law, finance).</li>
</ul>

<p><strong>Practical Use</strong>:</p>
<ul>
  <li>Simple translations with additional control over translation quality, style, and domain-specific language.</li>
</ul>

<h1 id="amazon-lex">Amazon Lex</h1>
<ul>
  <li>Conversational interface supporting voice and text-chat.</li>
  <li>Utilizes Alexa’s conversational engine.</li>
  <li>Fully managed service with automatic scaling, backup, and versioning.</li>
</ul>

<p><strong>Conversation Example</strong>: Booking a car.</p>
<ul>
  <li>Key elements: Destination city and departure date.</li>
</ul>

<p><strong>Bot Configuration in Amazon Lex</strong>:</p>
<ul>
  <li><strong>Intents</strong>: Tasks to complete via conversation (e.g., BookCar).</li>
  <li><strong>Utterances</strong>: Phrases triggering an intent.</li>
  <li><strong>Slots</strong>: Parameters required to fulfill an intent.</li>
  <li><strong>Prompts</strong>: Questions eliciting slot responses.</li>
</ul>

<p><strong>Intent Configuration</strong>:</p>
<ul>
  <li><strong>PromptSpecification</strong>: Message confirming intent completion.</li>
  <li><strong>DeclinationResponse</strong>: Used if user refuses promptSpecification.</li>
  <li><strong>DialogCodeHook</strong>: AWS Lambda function for additional conversational logic.</li>
  <li><strong>FulfillmentCodeHook</strong>: Passes completed intent to a Lambda function for processing or local device actions.</li>
</ul>

<p><strong>Slot Types</strong>:</p>
<ul>
  <li>Defined questions for user response.</li>
  <li>EnumerationValues for training or validation.</li>
  <li>Two modes: Expand values (training data) or restrict to set values (validation).</li>
</ul>

<p><strong>Built-in Intents and Slot Types</strong>:</p>
<ul>
  <li>Common intents (e.g., HelpIntent, CancelIntent) and slot types (e.g., dates, numbers) pre-configured.</li>
</ul>

<p><strong>Integration with External Systems</strong>:</p>
<ul>
  <li>Customization of user interactions.</li>
  <li>Integration with databases or external systems via Lambda functions.</li>
  <li><strong>DialogCodeHook</strong>: Initialization and validation.</li>
  <li><strong>FulfillmentCodeHook</strong>: Post-intent processing and direction.</li>
</ul>

<p><strong>Lambda Function Integration</strong>:</p>
<ul>
  <li>Receives context (bot, intent, slots) for processing.</li>
  <li>Directs Lex for next steps using dialog actions (e.g., Close, ConfirmIntent, Delegate, ElicitIntent, ElicitSlot).</li>
</ul>

<h1 id="amazon-sagemaker">Amazon SageMaker</h1>
<ul>
  <li>Designed for preparing, building, training, and deploying machine learning models.</li>
  <li>Offers fine control over model creation and deployment.</li>
</ul>

<p><strong>Jupyter Notebooks in SageMaker</strong>:</p>
<ul>
  <li>Interactive environment for code, documentation, and visualizations.</li>
  <li>Supports data preparation, visualization, training, and deploying models.</li>
  <li>Can clone and run notebooks from GitHub.</li>
</ul>

<p><strong>Training a Model in SageMaker</strong>:</p>
<ul>
  <li>Variety of algorithms available: SageMaker-provided, custom, or from AWS Marketplace.</li>
  <li>Custom algorithms via Docker containers.</li>
  <li>Selection of training instance types (standard, compute-optimized, GPU-accelerated).</li>
  <li>Hyperparameter tuning for algorithm optimization.</li>
  <li>Input data channels from S3 or EFS, format depends on the algorithm.</li>
</ul>

<p><strong>AWS Marketplace</strong>:</p>
<ul>
  <li>Buy or sell trained models and algorithms.</li>
  <li>Marketplace offers pre-trained models or algorithms for training.</li>
</ul>

<p><strong>Hosting Models for Inferences</strong>:</p>
<ul>
  <li><strong>Real-Time Inference</strong>: API endpoint for real-time model access.</li>
  <li><strong>Serverless Inference</strong>: Cost-effective for infrequent or unpredictable traffic.</li>
  <li><strong>Asynchronous Endpoint</strong>: Queues requests for processing with large payloads/long processing times.</li>
  <li><strong>Batch Transformation</strong>: Process data in batches without a long-lived endpoint.</li>
</ul>

<p><strong>Practical Applications</strong>:</p>
<ul>
  <li>Real-time applications like fraud detection.</li>
  <li>Batch processing for non-real-time requirements.</li>
</ul>

<p><strong>Further Learning in SageMaker</strong>:</p>
<ul>
  <li>Advanced machine learning capabilities for deeper exploration.</li>
</ul>]]></content><author><name>Kartik</name></author><category term="Jekyll" /><summary type="html"><![CDATA[Artificial intelligence is the larger field of study using computers to do processes generally done by the human brain.]]></summary></entry><entry><title type="html">SQL</title><link href="http://localhost:4000/jekyll/2024-01-05-SQL.html" rel="alternate" type="text/html" title="SQL" /><published>2024-01-05T00:00:00-05:00</published><updated>2024-01-05T00:00:00-05:00</updated><id>http://localhost:4000/jekyll/SQL</id><content type="html" xml:base="http://localhost:4000/jekyll/2024-01-05-SQL.html"><![CDATA[<h1 id="1-selecting-and-retrieving-data-with-sql">1 Selecting and Retrieving Data with SQL</h1>

<h2 id="11-what-is-sql">1.1 What is SQL?</h2>
<p>Structured Query Language (SQL): standard computer language for data management and data manipulation. It is the way you can communicate with databases. It is a non-procedural language, meaning you cannot write complete applications with it however you will be able to read, write, and update data.</p>

<p>Just because SQL is the language you are using, there are differences in the syntax depending on the database management system (DBMS) you are using.</p>

<h2 id="12-data-models">1.2 Data Models</h2>
<p>Databases: a container to store organized data; a set of related information.</p>

<p>Tables: a structured list of data or a specific type.</p>
<ul>
  <li>Columns: a single field in a table</li>
  <li>Rows: a record in a table</li>
</ul>

<p>What is data modelling? Organizes and structures information into multiple, related tables. Can represent a business process or show relationships between business processes. <em>Data models should closely represent the real world processes</em></p>

<p>NoSQL (not only SQL): a mechanism for storage and retrieval of unstructured data modelled by means other than tabular relations in relational databases.</p>

<p>All relational models have an entity, attribute, and relationship.</p>
<ul>
  <li>Entity: person, place, thing, or event. Distinguishable, unique and distinct.</li>
  <li>Attribute: characterstic of an entity.</li>
  <li>Relationship: describes association among entities (e.g., one-to-many, many-to-many, one-to-one)</li>
</ul>

<p>ER diagrams depict the relationships between tables. Helps represent business processes. Joined by primary-foreign keys.</p>
<ul>
  <li>Primary keys: a column (or set of columns) whose values uniquely identify every row in a table.</li>
  <li>Foriegn key: one or more columns that can be used together to identify a single row in another table.</li>
  <li>Different types of notation (Chen Notation, Crow’s Foot Notation, UML Class Diagram Notation)</li>
</ul>

<h2 id="13-retrieving-data-with-a-select-statement">1.3 Retrieving data with a SELECT statement</h2>

<p>The select statement you need to specific what you want and where you want it from.</p>

<pre><code class="language-SQL">SELECT item1,
        item2,
        item3
FROM tableName;
</code></pre>
<p>Selects items 1-3 from tableName.</p>

<pre><code class="language-SQL">SELECT *
FROM tableName;
</code></pre>
<p>Selects all items from tableName.</p>

<p>A lot of times you want to limit results (e.g., when the database is large). To select a sample from the database.</p>

<pre><code class="language-SQL">SELECT columnsYouWantToSee
FROM tableName
LIMIT 5;
</code></pre>
<p>Will show you the first 5 columns you want to see from tableName.</p>

<p>*Note: LIMITS have different syntaxes across DBMS.</p>

<h2 id="14-creating-tables">1.4 Creating tables</h2>

<p>Creating tables is useful if you want to extract data from other sources.</p>

<pre><code class="language-SQL">CREATE TABLE tableName (
    Id   char(10)    PRIMARY KEY,
    Variable1   char(10)    NOT NULL,
    Variable2   char(250)   NOT NULL,
    Variable3   decimal(8,2)  NOT NULL,
    Variable4   Varchar(750)    NULL
);
</code></pre>
<h3 id="141-nulls-and-primary-keys">1.4.1 Nulls and primary keys</h3>
<p>Every column is either NULL or NOT NULL. You will receive an error if you omit this with no value. *Note: Do not confuse null values with empty strings**. Primary keys cannot be null.</p>

<p>Primary keys MUST have a value.</p>

<h3 id="142-adding-data-to-the-table">1.4.2 Adding data to the table</h3>
<p>Two ways described below.</p>

<pre><code class="language-SQL">INSERT INTO tableName
VALUES ('000001', 
    'StringValue1', 
    'Stringvalue2', 
    '10.45', 
    NULL
    );
</code></pre>
<p>Using INSERT. This is not a recommended way because you are manually inserting values into columns and if you mess up the order, the entry will be wrong.</p>

<pre><code class="language-SQL">INSERT INTO tableName (
    Id, 
    Variable1, 
    Variable2, 
    Variable3, 
    Variable4
    )
VALUES (
    '000001', 
    'StringValue1', 
    'Stringvalue2', 
    '10.45', 
    NULL
    );
</code></pre>
<p>Now you are guaranteeing that the values are going into the right column.</p>

<h3 id="143-creating-temporary-tables">1.4.3 Creating temporary tables</h3>
<p>Temporary tables will be deleted when the current session is terminated. Faster than creating a real table. Useful for complex queries using subsets and joints.</p>

<pre><code class="language-SQL">CREATE TEMPORARY TABLE tmpTableName AS (
    SELECT *
    FROM tableName
    WHERE variableName1 = "conditionalString"
);
</code></pre>
<p>Depending on the DBMS, you will not be able to write data to temporary tables.</p>

<h3 id="144-adding-comments-to-sql">1.4.4 Adding comments to SQL</h3>
<p>Mutes the expression of code. Also helps you remember what and why you were doing.</p>

<p>Two ways to add comments</p>

<p>Single line comments</p>
<pre><code class="language-SQL">SELECT variableName1,
--variableName2,
variableName3
from tableName
</code></pre>
<p>The above comments out variableName2.</p>

<p>Section comments</p>
<pre><code class="language-SQL">SELECT variableName1,
/* variableName2,
variableName3 */
from tableName
</code></pre>
<p>The above comments out variableName2, and variableName3.</p>

<h2 id="15-star-schema-vs-snowflake-schema">1.5 Star Schema vs Snowflake Schema</h2>

<p>These are two types of datawarehouse models. They are ways to organize data using relational databases.</p>

<p>Star schema: Aggregated central fact table that contains relationships to dimension tables.</p>

<p>Snowflake schema: Stores the same data as the star schema however the main difference is that the dimensional tables in the snowflake schema are normalized producing <em>snowflaking</em>.</p>

<h3 id="151-first-difference-normalization">1.5.1 First difference: Normalization</h3>

<p>Snowflake schemas will use less space to store dimension tables because normalized databases produce far fewer redundant records. As a result of this, denormalized data models increase the chance of data integrity issues where records across dimension tables start to vary.</p>

<h3 id="152-second-difference-query-complexity">1.5.2 Second difference: Query complexity</h3>

<p>Snowflake schemas, because the dimension tables are normalized, require more complex querying. In star schema, you will only join the fact table with dimension tables you need - you will only have one JOIN per dimension table. In snowflake schema querying, you will need to use multiple joins to find the right dimension. Because of this, querying takes slightly longer in snowflake schema however the absolute difference is meaningless (e.g., 1ms vs 1s).</p>

<p><a href="https://www.vertabelo.com/blog/data-warehouse-modeling-star-schema-vs-snowflake-schema/">Source for snowflake vs star schema</a></p>

<h1 id="2-filtering-sorting-and-calculating-data-with-sql">2 Filtering, Sorting, and Calculating Data with SQL</h1>

<h2 id="21-basics-of-filtering-with-sql">2.1 Basics of Filtering with SQL</h2>

<p>Allows you to narrow the data you want to retrieve, reduce the number of records you retrieve, increase query performance, reduce the strain on the client application, and governance limitations.</p>

<h3 id="211-where-clause-operator">2.1.1 WHERE clause operator</h3>
<pre><code class="language-SQL">SELECT *
FROM tableName
WHERE columnName operator value;
</code></pre>

<p>List of operators:</p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">=</code> equal</li>
  <li><code class="language-plaintext highlighter-rouge">&lt;&gt;</code> not equal (in some operators it may be written as !=)</li>
  <li><code class="language-plaintext highlighter-rouge">&gt;</code> greater than</li>
  <li><code class="language-plaintext highlighter-rouge">&lt;</code> less than</li>
  <li><code class="language-plaintext highlighter-rouge">&gt;=</code> greater than or equal</li>
  <li><code class="language-plaintext highlighter-rouge">&lt;=</code> less than or equal to</li>
  <li><code class="language-plaintext highlighter-rouge">BETWEEN</code> between an inclusive range
    <ul>
      <li>You need to specific the range (e.g., WHERE columnName BETWEEN value1 AND value2;)</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">IS NULL</code> is a null value</li>
</ol>

<h2 id="22-advanced-filtering-in-or-not">2.2 Advanced Filtering: IN, OR, NOT</h2>

<h3 id="221-in-operator">2.2.1 IN operator</h3>
<p>Specifics a range of conditions. Comma deliminted list of values. Enclosed in ().</p>

<pre><code class="language-SQL">SELECT variableName
FROM tableName
WHERE variableName IN (value1, value2, value3)
</code></pre>

<h3 id="222-or-operator">2.2.2 OR operator</h3>

<p>DBMS will not evaluate the second conditions in a WHERE clause if the first condition is met. Use for any rows matching the specific conditions.</p>

<pre><code class="language-SQL">SELECT variableName
FROM tableName
WHERE variableName = 'string1' OR 'string2';
</code></pre>

<h3 id="223-in-vs-or">2.2.3 IN vs OR</h3>

<p>In works the same as OR, however there are some benefits of IN</p>
<ul>
  <li>Long list of options</li>
  <li>IN executes faster than OR</li>
  <li>Don’t have to think about the order with IN</li>
  <li>Can contain another select</li>
</ul>

<h3 id="224-order-with-and">2.2.4 ORDER with AND</h3>

<p>SQL will process an AND before an OR, so you will need to include parathesis to specific the groups.</p>

<h3 id="225-not-operator">2.2.5 NOT operator</h3>

<p>A way to exclude certain variables.</p>

<pre><code class="language-SQL">SELECT *
FROM tableName
WHERE NOT variableName = 'string1' AND 
NOT variableName = 'string2';
</code></pre>

<h2 id="23-using-wildcards-in-sql">2.3 Using Wildcards in SQL</h2>

<h3 id="231-percent--wildcard">2.3.1 Percent (%) wildcard</h3>
<p>Wildcards: special character used to match parts of a value. Search pattern made from literal text, wildcard charracter, or a combination. Uses <code class="language-plaintext highlighter-rouge">LIKE</code> as an operator (though technically a predicate). Can only be used with strings and not non-text datatypes.</p>

<p>To use a wildcard, you use a <code class="language-plaintext highlighter-rouge">%</code> before, in the middle, and/or after the word.</p>

<p>Another way to use a wildcard is to put it between letters to produce a more dynamic search. (E.g., <code class="language-plaintext highlighter-rouge">t%@gmail.com</code> will grab gmail addresses that start with “t”).</p>

<p>% wildcars will not match null values. NULL represents no value in a column.</p>

<pre><code class="language-SQL">SELECT variableName1, variableName2
FROM tableName
WHERE variableName2 LIKE '%substring'
</code></pre>

<h3 id="232-underscore-_-wildcard">2.3.2 Underscore (_) wildcard</h3>

<p><code class="language-plaintext highlighter-rouge">_</code> will match a single character (however not supported in all DBMSs)</p>

<p>Instead of <code class="language-plaintext highlighter-rouge">%</code> which will match any length string, <code class="language-plaintext highlighter-rouge">_</code> will only match a single character.</p>

<h3 id="233-bracket--wildcard">2.3.3 Bracket [] wildcard</h3>

<p>Used to specific a set of characters in a specific location (also does not work with all DBMSs)</p>

<h3 id="234-downsides-of-wildcards">2.3.4 Downsides of wildcards</h3>

<p>Takes longer to run so better to use other operators. Statements with wildcards will take longer to run if used at the end of search patterns (so placement of wildcards is important).</p>

<h2 id="24-sorting-with-order-by">2.4 Sorting with ORDER BY</h2>

<p>Why sort data? Data displayed appears in the order of the underlying tables. Updated and deleted data can change this order. Sequence of retrieved data cannot be assumed if order was not specified? Sorting data logically helps keep information you want on top. <code class="language-plaintext highlighter-rouge">ORDER BY</code> clause allows user to sort data by particular columns</p>

<pre><code class="language-SQL">SELECT *
FROM tableName
ORDER BY variableName43
</code></pre>

<h3 id="241-rules-for-order-by">2.4.1 Rules for ORDER BY</h3>

<p>Takes the name of one or more columns. Add a comma after each additional column name. You can sort by a column not retrieved (in the original SELECT statement). Must always be the last clause in a select statement.</p>

<h3 id="242-sorting-by-column-position">2.4.2 Sorting by column position</h3>

<pre><code class="language-SQL">ORDER BY 2,3
</code></pre>
<p>Will sort by column position where 2 means 2nd column, and 3 means 3rd column, etc.</p>

<h3 id="243-sort-direction">2.4.3 Sort direction</h3>

<p><code class="language-plaintext highlighter-rouge">DESC</code> for descending order</p>

<p><code class="language-plaintext highlighter-rouge">ASC</code> for ascending order</p>

<p>Only applies to the column names it directly precedes.</p>

<h2 id="25-math-operations">2.5 Math operations</h2>
<p><code class="language-plaintext highlighter-rouge">+</code>, <code class="language-plaintext highlighter-rouge">-</code>, <code class="language-plaintext highlighter-rouge">*</code>, <code class="language-plaintext highlighter-rouge">/</code></p>

<pre><code class="language-SQL">SELECT variableName1, 
    variableName2, 
    variableName3 * variableName1 AS variableName4
FROM tableName
</code></pre>

<p>Creates a new column based on the math operation between variable1 and variable3.</p>

<h3 id="251-order-of-operations">2.5.1 Order of operations</h3>

<p>Parantheses, exponents, multiplication, division, addition, substraction</p>

<h3 id="252-combining-math-operations">2.5.2 Combining math operations</h3>

<pre><code class="language-SQL">SELECT variableName1, 
    variableName2, 
    variableName3
    (variableName4 - variableName3) * variableName1 AS variableName5
FROM tableName
</code></pre>

<h2 id="26-aggregate-functions">2.6 Aggregate functions</h2>

<p>Provide various ways to summarize data. Useful for finding highest/lowest values, total number of rows, or average values.</p>

<p><code class="language-plaintext highlighter-rouge">AVG()</code> averages a column of values<br />
<code class="language-plaintext highlighter-rouge">COUNT()</code> counts the number of values<br />
<code class="language-plaintext highlighter-rouge">MIN()</code> finds the minimum value<br />
<code class="language-plaintext highlighter-rouge">MAX()</code> finds the maximum value<br />
<code class="language-plaintext highlighter-rouge">SUM()</code> sums the column value</p>

<pre><code class="language-SQL">SELECT AVG(variableName) AS variableNameAlias
FROM tableName
</code></pre>

<p>Rows containing null values will be ignored.</p>

<p><code class="language-plaintext highlighter-rouge">COUNT(*)</code> will count all the rows in a table containing values or NULL values</p>

<p><code class="language-plaintext highlighter-rouge">COUNT(variableName)</code> will count all rows in a specific column while ignoring NULL values</p>

<pre><code class="language-SQL">SELECT MIN(variableName) as min_value,
    MAX(variableName) as max_value
FROM tableName
</code></pre>
<p>MIN/MAX will ignore null values</p>

<pre><code class="language-SQL">SELECT SUM(variableName1*variableName2) AS variableNameAlias
FROM tableName
WHERE variableName3 = 'valueID';
</code></pre>

<p>Will do math operations on data that matches condition and store the new value as a new column.</p>

<h3 id="261-using-distinct-on-aggregate-functions">2.6.1 Using DISTINCT on Aggregate functions</h3>

<p>If DISTINCT is not specified, ALL is assumed. Cannot use DISTINCT on COUNT(*). No value to use with MIN and MAX functions.</p>

<pre><code class="language-SQL">SELECT COUNT(DISTINCT variableName)
FROM tableName
</code></pre>

<h2 id="27-grouping-data-with-sql">2.7 Grouping data with SQL</h2>

<h3 id="271-grouping-data">2.7.1 Grouping data</h3>

<pre><code class="language-SQL">SELECT variableName1,
    COUNT(variableName2) AS variableName3
FROM tableName
GROUP BY variableName1
</code></pre>
<p>if you did not have the group by, it would count the whole table.</p>

<p>GROUP BY clauses can contain multiple columns.</p>

<p>Every column in your SELECT statement MUST be present in a GROUP BY clause, except for the aggregated calculations.</p>

<p>NULLs will be grouped together if your GROUP BY column contain NULLs.</p>

<h3 id="272-having-clause---filtering-for-groups">2.7.2 HAVING Clause - Filtering for groups</h3>

<p>WHERE does not work for groups. WHERE filters on rows. Instead, use HAVING clause to filter for groups.</p>

<pre><code class="language-SQL">SELECT variableName1,
    COUNT (*) AS variableName2
FROM tableName
GROUP BY variableName1
HAVING COUNT (*) &gt;= 2;
</code></pre>
<p>Counts variableName1 that had more than 2 of variableName2.</p>

<h3 id="273-where-vs-having">2.7.3 WHERE vs. HAVING</h3>

<p>WHERE filters before data is grouped.</p>

<p>HAVING filters after data is grouped.</p>

<p>Rows eliminated by the WHERE clause will not be a included in the group.</p>

<h3 id="274-order-by-with-group-by">2.7.4 ORDER BY with GROUP BY</h3>

<p>ORDER BY sorts data.</p>

<p>GROUP BY does not sorta data.</p>

<h1 id="3-subqueries-and-joins-in-sql">3 Subqueries and Joins in SQL</h1>

<h2 id="31-using-subqueries">3.1 Using Subqueries</h2>

<p>Subqueries: Queries embedded in other queries. Relational databases store data across multiple tables. Subqueries merge data from multiple sources together. Helps with adding other filtering criteria.</p>

<pre><code class="language-SQL">SELECT CustomerID, 
    CompanyName, 
    Region
FROM Customers
WHERE CustomerID in (SELECT customerID
    FROM Orders
    WHERE Freight &gt; 100);
</code></pre>
<p>Example from Coursera. In the above example, we queried the Orders table to get customerID with Freight over 100 to look up their CompanyName and Region. We used subquering to filter one table to retrieve data from another.</p>

<p>The query will always perform the innermost SELECT portion first.</p>

<h2 id="32-subquery-best-practices-and-considerations">3.2 Subquery best practices and considerations</h2>

<p>There is no limit to the number of subqueries you can have. Performance slows when you nest too deeply.</p>

<p><strong>Subquery selects can only retrieve a single column</strong></p>

<p>Properly indent subqueries to know where each SELECT statement starts and ends.
<a href="www.poorsql.com">www.poorsql.com</a> will reformat code with proper indenting.</p>

<h3 id="321-subqueries-for-calculations">3.2.1 Subqueries for calculations</h3>

<pre><code class="language-SQL">SELECT customer_name,
    customer_state
    (SELECT COUNT(*) AS orders
    FROM Orders
    WHERE Orders.customer_id = Customer.customer_id) AS orders
FROM customers
ORDER BY Customer_name
</code></pre>
<p>The subquery is enclosed in the brackets. Retrieves the total number of orders placed by each customer.</p>

<h2 id="33-joining-tables-an-introduction">3.3 Joining tables: An introduction</h2>

<p>The reasons why we break data into multiple tables</p>
<ol>
  <li>Efficient storage</li>
  <li>Easier manipulations</li>
  <li>Greater scalability</li>
  <li>Logically models a process</li>
  <li>Tables are related through common values (i.e., keys)</li>
</ol>

<h3 id="331-joins">3.3.1 Joins</h3>

<p>Associates correct records from each table on the fly. Allows data retrieval from multiple tables in one query. Joins are not physical - they persist for the duration of the query execution.</p>

<h2 id="34-cartesian-cross-joins">3.4 Cartesian (Cross) Joins</h2>

<p>What is a Cartesian (Cross) join? Each row from the first table joins with all the rows of another table.</p>
<ul>
  <li>Computational expensive (e.g., a table with x rows and another with y rows will produce a new table of x * y rows)</li>
</ul>

<pre><code class="language-SQL">SELECT variableName1,
    variableName2,
    variableName3
FROM tableName1 CROSS JOIN tableName2;
</code></pre>

<p>This is a simple join that you can do, <strong>but it does not match anything</strong>. Therefore, it will return products with the incorrect information (therefore, it is not frequently used).</p>

<h2 id="35-inner-joins">3.5 Inner joins</h2>

<p>Inner joins: used to select records that have matching values (usually by keys) in both tables.</p>

<pre><code class="language-SQL">SELECT variableName1,
    variableName2,
    variableName3
FROM tableName1 INNER JOIN tableName2
ON tableName1.keyName = tableName2.keyName;
</code></pre>
<p>NOTE: If you have a common variableName that is found in both tables, you need to prequalify the variableName (that is a column name) with the table Name. E.g., <code class="language-plaintext highlighter-rouge">SELECT tableName1.variableName1,</code> if variableName1 is found in both.</p>

<p>You can perform on multiple tables. But becareful not to overly join because they are computationally taxing.</p>

<pre><code class="language-SQL">SELECT a.variableName1,
    b.variableName2,
    c.variableName3
FROM (
        (
        tableName1 a INNER JOIN tableName2 b ON a.keyName = b.keyName
        )
        INNER JOIN tableName3 c ON a.keyName = c.keyName
    );
</code></pre>

<p>Be as specific which table a column is from.</p>

<h2 id="36-aliases-and-self-joins">3.6 Aliases and self joins</h2>

<h3 id="361-aliases">3.6.1 Aliases</h3>
<p>Alias: shortens a table or a column with a temporary name. Makes it more readable and does not physically change the table/column name.</p>

<pre><code class="language-SQL">SELECT variableName1, 
    variableName2
FROM tableName1 as t1, 
    and tableName2 as t2
WHERE t1.keyName = t2.keyName;
</code></pre>

<h3 id="362-self-joins">3.6.2 Self joins</h3>
<p>When you join a table to itself.</p>

<pre><code class="language-SQL">SELECT t1.variableName1 as name1, 
    t2.variableName1 as name2,
    t1.variableName2
FROM tableName1 t1,
    tableName2 t2
WHERE t1.keyName = t2.keyName
    AND t1.variableName2 = t2.variableName2
ORDER BY t1.variableName2
</code></pre>

<p>The following matches variableName1 that have the same variableName2.</p>

<h2 id="37-advanced-joins-left-right-and-full-outer-joins">3.7 Advanced Joins: left, right, and full outer joins</h2>

<h3 id="371-left-joins">3.7.1 Left Joins</h3>
<p>Returns all records from the left table (table1) and the matched records from the right table (table2).</p>

<p>The result is NULL from the right side, if there is no match.</p>

<p>E.g., if Table1 is a customers table and Table2 is an orders table. A left join would produce a new table with all the customers and their associated order information (or null if no order).</p>

<pre><code class="language-SQL">SELECT C.CustomerName, 
    O.OrderID
FROM Customers C
LEFT JOIN Orders O ON C.CustomerID = O.CustomerID
ORDER BY C.CustomerName;
</code></pre>

<h3 id="372-right-joins">3.7.2 Right Joins</h3>
<p>Returns all records from the right table (table2) and the matched records from left table (table1).</p>

<p>The result is NULL from the left side, when there is no match.</p>

<p>E.g., if Table1 is a employees table and Table2 is an orders table. A right join would produce a new table with all the orders and the employees associated with the orders.</p>

<pre><code class="language-SQL">SELECT O.OrderID, 
    E.LastName, 
    E.FirstName
FROM Orders O
RIGHT JOIN Employees E ON O.EmployeeID = E.EmployeeID
ORDER BY O.OrderID;
</code></pre>

<h3 id="373-difference-between-right-and-left">3.7.3 Difference between right and left</h3>
<p>If you switch the order of when the tables appear, a left join can be turned into right joins and vice versa.</p>

<h3 id="374-full-outer-joins">3.7.4 Full Outer Joins</h3>
<p>Returns all records when there is a match in either left (table1) or right (table2) table records.</p>

<p>Gives you everything.</p>

<pre><code class="language-SQL">SELECT C.CustomerName,
    O.OrderID
FROM Customers C
FULL OUTER JOIN Orders O ON C.CustomerID=O.CustomerID
ORDER BY C.CustomerName;
</code></pre>

<h2 id="38-unions">3.8 Unions</h2>
<p>The UNION operator is used to combine the result-set of two or more SELECT statements. Each SELECT statement within UNION must have the same number of columns. Columns MUST have similar data types. The columns in each SELECT statement MUST be in the same order.</p>

<p>Sort of like appending two tables on top of each other.</p>

<pre><code class="language-SQL">SELECT variableName(s)
FROM tableName1
UNION
SELECT variableName(s)
FROM tableName2;
</code></pre>

<pre><code class="language-SQL">SELECT variableName1, 
    variableName2
FROM tableName1
WHERE variableName2='someString'
UNION
SELECT variableName1, 
    variableName2
FROM tableName2
WHERE variableName2='someString'
ORDER BY variableName1
</code></pre>

<h3 id="381-union-vs-union-all">3.8.1 Union vs Union All</h3>

<p>The UNION command is used to select related information from two tables, much like the JOIN command. However, when using the UNION command all selected columns need to be of the same data type. With UNION, only distinct values are selected.</p>

<p>The UNION ALL command is equal to the UNION command, except that UNION ALL selects all values.</p>

<p>The difference between Union and Union all is that Union all will not eliminate duplicate rows, instead it just pulls all rows from all tables fitting your query specifics and combines them into a table.</p>

<p><a href="https://blog.sqlauthority.com/2009/03/11/sql-server-difference-between-union-vs-union-all-optimal-performance-comparison/">From SQL Authority</a></p>

<h1 id="4-modifying-and-analyzing-data-with-sql">4 Modifying and Analyzing Data with SQL</h1>

<h2 id="41-working-with-text-strings">4.1 Working with text strings</h2>
<p>Allows you to retrieve the data in the format you need. There are differences between client vs server formatting.</p>

<p>Support joins</p>

<p>String functions</p>
<ol>
  <li>Concatenate</li>
  <li>Substring</li>
  <li>Trim</li>
  <li>Upper</li>
  <li>Lower</li>
</ol>

<h3 id="411-concatenate">4.1.1 Concatenate</h3>

<pre><code class="language-||```">
```SQL
SELECT variableName1, 
    variableName2,
    variableName3 || ' ('|| variableName4||')'
FROM tableName
</code></pre>
<p>Concatenates the variableName3 and variableName4. In the above example we are adding variableName4 in between ().</p>

<table>
  <tbody>
    <tr>
      <td>NOTE: SQL server supports + instead of</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h3 id="412-substring">4.1.2 Substring</h3>
<p>Returns the specified number of characters from a particular position of a given string.</p>

<pre><code class="language-SQL">SUBSTR(string name, string position, number of characters to be returned);
</code></pre>

<pre><code class="language-SQL">SELECT firstName, SUBSTR(firstName,3,4)
FROM labMembers
WHERE labName="JMT";
</code></pre>
<p>Gives the 3-7 characters of the first name of lab members that belong to the JMT Lab.</p>

<h3 id="413-trim">4.1.3 Trim</h3>

<p>Trims the leading or trailing space from a string (e.g., TRIM, RTRIM, LTRIM)</p>

<pre><code class="language-SQL">SELECT TRIM("     This is an example string.      ") AS TrimmedString;
</code></pre>

<p>The above trims left and right trailing space.</p>

<h3 id="414-upper-and-lower">4.1.4 Upper and Lower</h3>
<p>Changes case of string.</p>

<pre><code class="language-SQL">SELECT UPPER(variableName) FROM tableName;
</code></pre>

<pre><code class="language-SQL">SELECT UCASE(variableName) FROM tableName;
</code></pre>
<p>UCASE does the same as UPPER.</p>

<pre><code class="language-SQL">SELECT LOWER(variableName) FROM tableName;
</code></pre>

<h2 id="42-working-with-date-and-time-strings">4.2 Working with date and time strings</h2>

<p>Dates are stored as a datatype. Each DBMS uses it’s own variety of datatypes.</p>

<p>Having a time portion makes queries a bit more complex in contrast to just a date portion.</p>

<p>There are different formats</p>
<ul>
  <li>DATE Format: YYYY-MM-DD</li>
  <li>DATETIME Format: YYYY-MM-DD HH:MI:SS</li>
  <li>TIMESTAMP Format: YYYY-MM-DD HH:MI:SS</li>
</ul>

<p>SQLite supports 5 date and time functions:</p>

<pre><code class="language-SQL">DATE(timestring, modifier, modifier, ...)
TIME(timestring, modifier, modifier, ...)
DATETIME(timestring, modifier, modifier, ...)
JULIANDAY(timestring, modifier, modifier, ...)
STRFTIME(format, timestring, modifier, modifier, ...)
</code></pre>

<p>Timestrings can also be in a variety of formats.</p>

<pre><code class="language-SQL">YYYY-MM-DD
YYYY-MM-DD HH:MM
YYYY-MM-DD HH:MM:SS
YYYY-MM-DD HH:MM:SS.SSS
YYYY-MM-DDTHH:MM
YYYY-MM-DDTHH:MM:SS
YYYY-MM-DDTHH:MM:SS.SSS
HH:MM
HH:MM:SS
HH:MM:SS.SSS
</code></pre>

<p>Modifiers</p>
<ul>
  <li>NNN days</li>
  <li>NNN hours</li>
  <li>NNN minutes</li>
  <li>NNN.NNNN seconds</li>
  <li>NNN months</li>
  <li>NNN years</li>
  <li>start of month</li>
  <li>start of year</li>
  <li>start of day</li>
  <li>weekday N</li>
  <li>unixepoch</li>
  <li>localtime</li>
  <li>utc</li>
</ul>

<h3 id="date-and-time-string-examples">Date and Time String examples</h3>

<pre><code class="language-SQL">SELECT Birthdate,
    STRFTIME('%Y', Birthdate) AS Year,
    STRFTIME('%m', Birthdate) AS Month,
    STRFTIME('%d', Birthdate) AS Day
FROM labMembers
</code></pre>
<p>Flattens/Retrieves year, month, and day from a date string.</p>

<p>To compute the current date:</p>

<pre><code class="language-SQL">SELECT DATE('now')
</code></pre>

<pre><code class="language-SQL">SELECT STRFTIME('%Y %m %d', 'now')
</code></pre>

<p>You can compute operations</p>

<pre><code class="language-SQL">SELECT STRFTIME(('now') -Birthdate)
</code></pre>

<h2 id="43-case-statements">4.3 Case statements</h2>

<p>Mimics if-then-else statement found in most programming languages. Can be used in SELECT, INSERT, UPDATE, and DELETE statements</p>

<pre><code class="language-SQL">CASE
WHEN C1 THEN E1
WHEN C2 THEN E2
...
ELSE [result else]
END
</code></pre>

<pre><code class="language-SQL">SELECT employeeid,
    firstname,
    lastname,
    city,
    CASE City
        WHEN 'Calgary' THEN 'Calgary'
    ELSE 'Other'
        END calgary
FROM Employees
ORDER BY LastName, FirstName;
</code></pre>

<p>If you had a list of cities in a column but only wanted to create a column if the city was calgary or not.</p>

<p>You can also use CASE as a search (below).</p>

<pre><code class="language-SQL">CASE WHEN Boolean_expression
THEN result_expression [...n]
[ ELSE else_result_expression ]
END columnName
</code></pre>

<h2 id="44-views">4.4 Views</h2>

<p>A view is a stored query. Can add or remove columns without changing schema. Use it to encapsualte queries. The view will be removed after database connection has ended.</p>

<pre><code class="language-SQL">CREATE [TEMP] VIEW [IF NOT EXISTS] 
view_name(column-name-list)
AS
select-statements;
</code></pre>

<p>Example:</p>

<pre><code class="language-SQL">CREATE VIEW my_view
AS
SELECT
r.regiondescription,
t.territorydescription,
e.Lastname,
e.FirstName,
e.Hiredate,
e.Reportsto
FROM Region r
INNER JOIN Territories t on r.regionid = t.regionid
INNER JOIN Employeeterritories et on t.TerritoryID = et.TerritoryID
INNER JOIN Employees e on et.employeeid = e.EmployeeID
</code></pre>

<p>Here we combine three tables based on keys and create a View that contains select variables.</p>

<pre><code class="language-SQL">SELECT *
FROM view_name
</code></pre>

<p>To view the data, you will need to use a SELECT statement</p>

<pre><code class="language-SQL">DROP VIEW view_name
</code></pre>
<p>Drops the view.</p>

<p>Once you create a view, you can treat it as a normal table to run additional queries.</p>

<p>Views are useful to create stepping stones in multiple-level queries and prevents transfer of data during ETL processes. Only good for the SQL session.</p>

<h2 id="45-data-governance-and-profiling">4.5 Data Governance and Profiling</h2>

<p>Data profiling: when you look at descriptive statistics or object data information -examining data for completeness and accuracy. Helps understand the data. E.g., number of rows, table size, when the objects were last updated.</p>

<p>Column data profiling: column date type, number of distinct values, number of rows with NULL values, descriptive statistics (max, average, std for column values).</p>

<p>You need to test your data along the way during query generation.</p>

<h3 id="451-governance-best-practices">4.5.1 Governance best practices</h3>

<p>Depends on the organization. Understand the read and write capabilities. Clean up your environments after you’re done. Understand your promotion/value process.</p>

<h2 id="46-using-sql-for-data-science">4.6 Using SQL for data science</h2>

<h3 id="461-data-understanding">4.6.1 Data Understanding</h3>

<p>The most important step. Understand the relationships in your data (data and business understanding).</p>
<ul>
  <li>Data understanding: data types, contatenated date and times, etc.
    <ul>
      <li>Subject area understanding: may be new until you write more queries until you know how the data relates to each other. Understanding where data joins are. Differentiating integers from strings.</li>
    </ul>
  </li>
  <li>Business understanding: ask question about the business problem you are solving. Hard to separate date and business understanding.</li>
</ul>

<p>Beware of the unspoken need! These are specific details that are necessary to understand the business understanding (which are sometimes somewhat vague).</p>

<h3 id="462-profiling-data">4.6.2 Profiling data</h3>

<p>Get into the details of your data. Create a data model and map the fields and tables you need. Consider joins and calculations. Understand any data quality or format issues.</p>

<p>Start with SELECT</p>
<ul>
  <li>Start simple</li>
  <li>Any query begins with SELECT statement</li>
  <li>Add in special formatting</li>
  <li>If using subqueries, start with the inner-most query and work outward</li>
</ul>

<h3 id="463-test-and-troubleshoot">4.6.3 Test and troubleshoot</h3>
<p>Do not wait until the end to test queries. Test after each join or filter. Are you getting the results you expected. Start small and go step-by-step when troubleshooting a query.</p>

<h3 id="464-format-and-comment">4.6.4 Format and comment</h3>
<p>Use correct formatting and indentation. Comment strategically. Clean code and comments help when you revist or hand off code.</p>

<h3 id="465-review">4.6.5 Review</h3>
<p>Always review old queries, changes to business rules, data changes, data indicators. Work the problem from beginning to end.</p>]]></content><author><name>Kartik</name></author><category term="Jekyll" /><summary type="html"><![CDATA[1 Selecting and Retrieving Data with SQL]]></summary></entry></feed>